MPIDI_Process.*
  verbose               : 1
  statistics            : 0
  contexts              : 1
  async_progress        : 0
  context_post          : 0
  short_limit           : 113
  eager_limit           : 2049
  eager_limit_local     : 64
  rma_pending           : 1000
  shmem_pt2pt           : 1
  optimized.collectives : 1
  optimized.select_colls: 2
  optimized.subcomms    : 1
The following MPICH_* environment variables were specified:
The following PAMID_* environment variables were specified:
  PAMID_VERBOSE=1
The following PAMI_* environment variables were specified:
The following COMMAGENT_* environment variables were specified:
The following MUSPI_* environment variables were specified:
The following BG_* environment variables were specified:
  BG_SHAREDMEMSIZE=32
MPI was initialized. 
MPI thread support is THREAD_SINGLE. 
MPI test program running on 2048 ranks. 
MPI_Barrier on MPI_COMM_WORLD 1 
MPI_Comm_dup of MPI_COMM_WORLD 
MPI_Barrier on comm_world_dup 
MPI_Comm_split of MPI_COMM_WORLD into odd-even 
MPI_Barrier on comm_world_oddeven 
MPI_Comm_split MPI_COMM_WORLD into (world-1) 
MPI_Barrier on comm_world_minus_one 
MPI_Comm_group of group_world from MPI_COMM_WORLD 
geomprog_list[0] = 0 
geomprog_list[1] = 1 
geomprog_list[2] = 3 
geomprog_list[3] = 7 
geomprog_list[4] = 15 
geomprog_list[5] = 31 
geomprog_list[6] = 63 
geomprog_list[7] = 127 
geomprog_list[8] = 255 
geomprog_list[9] = 511 
geomprog_list[10] = 1023 
MPI_Group_incl of group_geomprog (geometric progression) from group_world 
MPI_Comm_create of comm_geomprog from group_geomprog on MPI_COMM_WORLD 
MPI_Barrier on comm_geomprog 
MPI_Barrier on MPI_COMM_WORLD 2 
============== BCAST ==============
0: MPI_Bcast 1 integers in 0.000020 seconds (0.195838 MB/s) 
0: MPI_Bcast 2 integers in 0.000010 seconds (0.830953 MB/s) 
0: MPI_Bcast 4 integers in 0.000009 seconds (1.773344 MB/s) 
0: MPI_Bcast 8 integers in 0.000009 seconds (3.617863 MB/s) 
0: MPI_Bcast 16 integers in 0.000009 seconds (7.176899 MB/s) 
0: MPI_Bcast 32 integers in 0.000010 seconds (12.715758 MB/s) 
0: MPI_Bcast 64 integers in 0.000010 seconds (26.841415 MB/s) 
0: MPI_Bcast 128 integers in 0.000010 seconds (52.111959 MB/s) 
0: MPI_Bcast 256 integers in 0.000010 seconds (105.119979 MB/s) 
0: MPI_Bcast 512 integers in 0.000011 seconds (193.824678 MB/s) 
0: MPI_Bcast 1024 integers in 0.000012 seconds (346.714633 MB/s) 
0: MPI_Bcast 2048 integers in 0.000014 seconds (567.411255 MB/s) 
0: MPI_Bcast 4096 integers in 0.000019 seconds (841.824021 MB/s) 
0: MPI_Bcast 8192 integers in 0.000029 seconds (1112.571089 MB/s) 
0: MPI_Bcast 16384 integers in 0.000049 seconds (1326.304073 MB/s) 
0: MPI_Bcast 32768 integers in 0.000086 seconds (1520.645049 MB/s) 
0: MPI_Bcast 65536 integers in 0.000138 seconds (1903.992011 MB/s) 
0: MPI_Bcast 131072 integers in 0.000120 seconds (4367.883698 MB/s) 
0: MPI_Bcast 262144 integers in 0.000198 seconds (5287.726531 MB/s) 
0: MPI_Bcast 524288 integers in 0.000483 seconds (4344.279385 MB/s) 
0: MPI_Bcast 1048576 integers in 0.004087 seconds (1026.207875 MB/s) 
0: MPI_Bcast 2097152 integers in 0.008115 seconds (1033.663785 MB/s) 
0: MPI_Bcast 4194304 integers in 0.016209 seconds (1035.036909 MB/s) 
============== BCAST VS SCATTER+ALLGATHER ==============
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 2048 integers in 0.000027 vs 0.000741 seconds (307.977161 vs 11.055387 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 4096 integers in 0.000020 vs 0.000416 seconds (817.462891 vs 39.406876 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 8192 integers in 0.000030 vs 0.000623 seconds (1102.603575 vs 52.598061 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 16384 integers in 0.000050 vs 0.000712 seconds (1321.690027 vs 92.103802 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 32768 integers in 0.000286 vs 0.001428 seconds (458.019455 vs 91.788561 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 65536 integers in 0.000631 vs 0.002979 seconds (415.252955 vs 87.988897 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 131072 integers in 0.001149 vs 0.005777 seconds (456.118769 vs 90.756295 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 262144 integers in 0.002474 vs 0.010778 seconds (423.782434 vs 97.289668 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 524288 integers in 0.006103 vs 0.023067 seconds (343.632255 vs 90.915769 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 1048576 integers in 0.014788 vs 0.042163 seconds (283.628049 vs 99.478334 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 2097152 integers in 0.036509 vs 0.082330 seconds (229.767167 vs 101.890111 MB/s) 
0: MPI_Bcast vs MPI_Scatter+MPI_Allgather 4194304 integers in 0.081265 vs 0.199552 seconds (206.449714 vs 84.074227 MB/s) 
============== ALLGATHER ==============
0: MPI_Allgather 2048 integers in 0.000231 seconds (35.508454 MB/s) 
0: MPI_Allgather 4096 integers in 0.000259 seconds (63.315219 MB/s) 
0: MPI_Allgather 8192 integers in 0.000381 seconds (85.960831 MB/s) 
0: MPI_Allgather 16384 integers in 0.000490 seconds (133.861336 MB/s) 
0: MPI_Allgather 32768 integers in 0.000994 seconds (131.894030 MB/s) 
0: MPI_Allgather 65536 integers in 0.003476 seconds (75.420600 MB/s) 
0: MPI_Allgather 131072 integers in 0.004937 seconds (106.191955 MB/s) 
0: MPI_Allgather 262144 integers in 0.013308 seconds (78.790694 MB/s) 
0: MPI_Allgather 524288 integers in 0.025557 seconds (82.057635 MB/s) 
0: MPI_Allgather 1048576 integers in 0.039221 seconds (106.940746 MB/s) 
0: MPI_Allgather 2097152 integers in 0.129624 seconds (64.714871 MB/s) 
0: MPI_Allgather 4194304 integers in 0.208435 seconds (80.491173 MB/s) 
============== ALLTOALL ==============
0: MPI_Alltoall 2048 integers in 0.001014 seconds (8.082383 MB/s) 
0: MPI_Alltoall 4096 integers in 0.000968 seconds (16.934279 MB/s) 
0: MPI_Alltoall 8192 integers in 0.000975 seconds (33.623724 MB/s) 
0: MPI_Alltoall 16384 integers in 0.000977 seconds (67.059337 MB/s) 
0: MPI_Alltoall 32768 integers in 0.001227 seconds (106.803561 MB/s) 
0: MPI_Alltoall 65536 integers in 0.001718 seconds (152.579513 MB/s) 
0: MPI_Alltoall 131072 integers in 0.002799 seconds (187.296050 MB/s) 
0: MPI_Alltoall 262144 integers in 0.004937 seconds (212.373102 MB/s) 
0: MPI_Alltoall 524288 integers in 0.009755 seconds (214.980282 MB/s) 
0: MPI_Alltoall 1048576 integers in 0.019455 seconds (215.588948 MB/s) 
0: MPI_Alltoall 2097152 integers in 0.039538 seconds (212.164654 MB/s) 
0: MPI_Alltoall 4194304 integers in 0.078202 seconds (214.536506 MB/s) 
