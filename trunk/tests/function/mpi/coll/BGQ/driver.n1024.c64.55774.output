MPIDI_Process.*
  verbose               : 1
  statistics            : 0
  contexts              : 1
  async_progress        : 0
  context_post          : 0
  pt2pt.limits
    application
      eager
        remote, local   : 4097, 4097
      short
        remote, local   : 113, 113
    internal
      eager
        remote, local   : 4097, 4097
      short
        remote, local   : 113, 113
  rma_pending           : 1000
  shmem_pt2pt           : 1
  disable_internal_eager_scale : 524288
  mp_buf_mem               : 0
  is_token_flow_control_on : 0
  optimized.collectives : 1
  optimized.select_colls: 2
  optimized.subcomms    : 1
  mpir_nbc              : 0
mpi thread level        : 'MPI_THREAD_SINGLE'
MPIU_THREAD_GRANULARITY : 'per object'
ASSERT_LEVEL            : 2
MPICH2_LIBDIR           : not defined
The following MPICH_* environment variables were specified:
The following PAMID_* environment variables were specified:
  PAMID_VERBOSE=1
The following PAMI_* environment variables were specified:
The following COMMAGENT_* environment variables were specified:
The following MUSPI_* environment variables were specified:
The following BG_* environment variables were specified:
MPI was initialized. 
MPI thread support is THREAD_SINGLE. 
MPI test program running on 65536 ranks. 
MPI_Barrier on MPI_COMM_WORLD 1 
MPI_Comm_dup of MPI_COMM_WORLD 
MPI_Barrier on comm_world_dup 
MPI_Comm_split of MPI_COMM_WORLD into world_reordered 
MPI_Comm_split of MPI_COMM_WORLD into left-right 
MPI_Barrier on comm_world_leftright 
MPI_Comm_split of MPI_COMM_WORLD into odd-even 
MPI_Barrier on comm_world_oddeven 
MPI_Comm_split MPI_COMM_WORLD into (world-1) 
MPI_Barrier on comm_world_minus_one 
MPI_Comm_group of group_world from MPI_COMM_WORLD 
geomprog_list[0] = 0 
geomprog_list[1] = 1 
geomprog_list[2] = 3 
geomprog_list[3] = 7 
geomprog_list[4] = 15 
geomprog_list[5] = 31 
geomprog_list[6] = 63 
geomprog_list[7] = 127 
geomprog_list[8] = 255 
geomprog_list[9] = 511 
geomprog_list[10] = 1023 
geomprog_list[11] = 2047 
geomprog_list[12] = 4095 
geomprog_list[13] = 8191 
geomprog_list[14] = 16383 
geomprog_list[15] = 32767 
MPI_Group_incl of group_geomprog (geometric progression) from group_world 
MPI_Comm_create of comm_geomprog from group_geomprog on MPI_COMM_WORLD 
MPI_Barrier on comm_geomprog 
MPI_Barrier on MPI_COMM_WORLD 2 
############## MPI_COMM_WORLD ##############
============== BCAST ==============
0: MPI_Bcast 1 integers in 0.000030 seconds (0.133679 MB/s) 
0: MPI_Bcast 2 integers in 0.000014 seconds (0.557491 MB/s) 
0: MPI_Bcast 4 integers in 0.000014 seconds (1.149322 MB/s) 
0: MPI_Bcast 8 integers in 0.000014 seconds (2.299883 MB/s) 
0: MPI_Bcast 16 integers in 0.000014 seconds (4.636421 MB/s) 
0: MPI_Bcast 32 integers in 0.000015 seconds (8.674291 MB/s) 
0: MPI_Bcast 64 integers in 0.000015 seconds (17.373600 MB/s) 
0: MPI_Bcast 128 integers in 0.000015 seconds (35.287530 MB/s) 
0: MPI_Bcast 256 integers in 0.000015 seconds (67.158551 MB/s) 
0: MPI_Bcast 512 integers in 0.000017 seconds (122.469726 MB/s) 
0: MPI_Bcast 1024 integers in 0.000018 seconds (227.634595 MB/s) 
0: MPI_Bcast 2048 integers in 0.000021 seconds (392.501647 MB/s) 
0: MPI_Bcast 4096 integers in 0.000027 seconds (613.632959 MB/s) 
0: MPI_Bcast 8192 integers in 0.000037 seconds (886.205439 MB/s) 
0: MPI_Bcast 16384 integers in 0.000058 seconds (1124.852230 MB/s) 
0: MPI_Bcast 32768 integers in 0.000194 seconds (676.657804 MB/s) 
0: MPI_Bcast 65536 integers in 0.000248 seconds (1057.952100 MB/s) 
0: MPI_Bcast 131072 integers in 0.001273 seconds (411.902875 MB/s) 
0: MPI_Bcast 262144 integers in 0.004897 seconds (214.129015 MB/s) 
0: MPI_Bcast 524288 integers in 0.009257 seconds (226.545537 MB/s) 
0: MPI_Bcast 1048576 integers in 0.017229 seconds (243.443074 MB/s) 
0: MPI_Bcast 2097152 integers in 0.034577 seconds (242.609513 MB/s) 
0: MPI_Bcast 4194304 integers in 0.067764 seconds (247.583852 MB/s) 
0: MPI_Bcast 8388608 integers in 0.133615 seconds (251.127882 MB/s) 
============== GATHER ==============
0: MPI_Gather 65536 integers in 0.001094 seconds (239.720541 MB/s) 
0: MPI_Gather 131072 integers in 0.001393 seconds (376.429705 MB/s) 
0: MPI_Gather 262144 integers in 0.002107 seconds (497.756047 MB/s) 
0: MPI_Gather 524288 integers in 0.003661 seconds (572.881608 MB/s) 
0: MPI_Gather 1048576 integers in 0.006991 seconds (599.975146 MB/s) 
0: MPI_Gather 2097152 integers in 0.013762 seconds (609.544349 MB/s) 
0: MPI_Gather 4194304 integers in 0.026558 seconds (631.727440 MB/s) 
0: MPI_Gather 8388608 integers in 0.021787 seconds (1540.093370 MB/s) 
============== ALLGATHER ==============
0: MPI_Allgather 65536 integers in 0.008571 seconds (30.584113 MB/s) 
0: MPI_Allgather 131072 integers in 0.023425 seconds (22.381804 MB/s) 
0: MPI_Allgather 262144 integers in 0.028333 seconds (37.009123 MB/s) 
0: MPI_Allgather 524288 integers in 0.126757 seconds (16.544702 MB/s) 
0: MPI_Allgather 1048576 integers in 0.239480 seconds (17.514199 MB/s) 
0: MPI_Allgather 2097152 integers in 0.380067 seconds (22.071404 MB/s) 
0: MPI_Allgather 4194304 integers in 0.919737 seconds (18.241318 MB/s) 
0: MPI_Allgather 8388608 integers in 1.585755 seconds (21.159904 MB/s) 
============== SCATTER ==============
0: MPI_Scatter 1 integers in 0.000698 seconds (0.005734 MB/s) 
0: MPI_Scatter 2 integers in 0.001241 seconds (0.006445 MB/s) 
0: MPI_Scatter 4 integers in 0.001943 seconds (0.008233 MB/s) 
0: MPI_Scatter 8 integers in 0.006371 seconds (0.005023 MB/s) 
0: MPI_Scatter 16 integers in 0.125872 seconds (0.000508 MB/s) 
0: MPI_Scatter 32 integers in 0.039345 seconds (0.003253 MB/s) 
0: MPI_Scatter 64 integers in 0.279801 seconds (0.000915 MB/s) 
