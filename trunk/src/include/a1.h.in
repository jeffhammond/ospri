/* -*- Mode: C; c-basic-offset:4 ; -*- */
/*
 *  Copyright (C) 2010 by Argonne National Laboratory.
 *      See COPYRIGHT in top-level directory.
 */

#if !defined OSP_H_INCLUDED
#define OSP_H_INCLUDED

/* Keep C++ compilers from getting confused */
#if defined(__cplusplus)
extern "C"
{
#endif /* __cplusplus */

#define OSP_SUCCESS 0
#define OSP_ERROR   1

/** @file osp.h.in */

/*! \addtogroup osp OSP Public Interface
 * @{
 */

/* ********************************************************************* */
/*                                                                       */
/*               Enumerations                                            */
/*                                                                       */
/* ********************************************************************* */

/**
 * \brief Thread support within OSP.
 *
 * Implementation details:
 *
 * OSP_THREAD_SINGLE, OSP_THREAD_FUNNELED, OSP_THREAD_SERIALIZED and
 * OSP_THREAD_MULTIPLE have the same meaning as the MPI descriptors
 * of similar name.
 *
 * \ingroup ENUMS
 *
 */

typedef enum
{
    OSP_THREAD_SINGLE,     /**< There is only one thread present. */
    OSP_THREAD_FUNNELED,   /**< There are multiple threads present
                               but only the main thread makes OSP calls. */
    OSP_THREAD_SERIALIZED, /**< There are multiple threads present and each can make OSP calls,
                               but never simultaneously. */
    OSP_THREAD_MULTIPLE    /**< There are multiple threads present and each can make OSP calls. */
} OSP_thread_level;

/**
 * \brief Datatype support within OSP.
 *
 * \note OSP does not support complex numbers yet.  This is okay because
 *       imaginary numbers don't exist, by definition :-)
 *
 * \ingroup ENUMS
 *
 */

typedef enum
{
    OSP_INT32,  /**< int32  */
    OSP_INT64,  /**< int64  */
    OSP_UINT32, /**< uint32 */
    OSP_UINT64, /**< uint64 */
    OSP_FLOAT,  /**< single-precision */
    OSP_DOUBLE, /**< double-precision */
} OSP_datatype_t;

/**
 * \brief OSP boolean.
 *
 * \ingroup ENUMS
 *
 */

typedef enum
{
    OSP_TRUE = 1,
    OSP_FALSE = 0,
} OSP_bool_t;

/**
 * \brief OSP result (error code).
 *
 * \ingroup ENUMS
 *
 */

typedef enum
{
    OSP_NO_ERROR = 0, /* Can't use OSP_SUCCESS since we're already using that.  Should fix this. */
    OSP_MEMORY_ERROR,
    OSP_NETWORK_ERROR,
    OSP_UNKNOWN_ERROR,
} OSP_result_t;

/**
 * \brief OSP reduction operations
 *
 * \ingroup ENUMS
 *
 */

typedef enum
{
    OSP_SUM,
    OSP_PROD,
    OSP_MAX,
    OSP_MIN,
    OSP_MAXABS, /* Returns MAX(ABS(buffer)) */
    OSP_MINABS, /* Returns MIN(ABS(buffer)) */
    OSP_OR,     /* should be only for integer types but I don't know if we check */
    OSP_BXOR,   /* bit-wise XOR - only for integer types */
    OSP_SAME,   /* Sets the return value if the buffer (element) is the same across all nodes.
                  This operation is equivalent to doing MAX(buffer) and MIN(-buffer) simultaneously
                  and testing for equality element-wise. */
} OSP_reduce_op_t;

/**
 * \brief OSP RMW operations
 *
 * \ingroup ENUMS
 *
 */

typedef enum
{
    OSP_FETCH_AND_ADD,
    OSP_SWAP,
} OSP_atomic_op_t;

/* ********************************************************************* */
/*                                                                       */
/*               OSP data structures                                      */
/*                                                                       */
/* ********************************************************************* */

/**
 * \brief OSP memregion type.
 *
 * \see OSP_Allocate_memregion, OSP_Free_memregion, OSP_Bind_memregion
 *
 * \ingroup TYPEDEFS
 *
 */

typedef struct OSP_memregion
{
    void* base_address;
    unsigned size;           /* Size in elements of type not bytes (unless bytes is type). */
    OSP_datatype_t type;      /* Not sure if this is the right idea but one can always use bytes. */
    void* memregion_options; /* This is a pointer to the device-specific memregion options that
                                 are the motivation for creating this struct in the first place. */
} OSP_memregion_t;

/**
 * \brief OSP offset type.
 *
 * \see OSP_PutMR
 *
 * \ingroup TYPEDEFS
 *
 */

typedef unsigned int OSP_offset_t;

/**
 * \brief OSP group type.
 *
 * \see OSP_PutMR
 *
 * \ingroup TYPEDEFS
 *
 */

/* TODO: Implement OSP group types.  I wonder if the user-accessible type should be
 *        a pointer to the internal implementation to prevent people from doing
 *        stupid kinds of direct access.
 */
/* FIXME: I really want to use a device-specific implementation of groups
 *         since this is critical for optimizing collectives on Blue Gene
 *         systems.  This also permits shared-memory optimizations in cases
 *         where the group is confined to a single node.  There will also
 *         be quirks arising in the GPU context I want to deal with directly.
 */
typedef struct OSP_group
{
    int* rank_list;
} OSP_group_t;

OSP_group_t osp_group_world;

#define OSP_GROUP_WORLD &osp_group_world

/**
 * \brief OSP endpoint type.
 *
 * \see OSP_PutMR
 *
 * \ingroup TYPEDEFS
 *
 */

typedef unsigned int OSP_endpoint_t;

/**
 * \brief OSP size type.
 *
 * \see OSP_PutMR
 *
 * \ingroup TYPEDEFS
 *
 */

typedef unsigned int OSP_size_t;

/**
 * \brief OSP non-blocking handle type.
 *
 * \see OSP_Test_handle, OSP_Test_handle_list,
 *      OSP_Wait_handle, OSP_Wait_handle_list,
 *      OSP_Reset_handle, OSP_Reset_handle_list
 *
 * \ingroup TYPEDEFS
 *
 */

typedef void* OSP_handle_t;

/**
 * \brief OSP shared counter.
 *
 * \ingroup TYPEDEFS
 *
 */

typedef void* OSP_counter_t;

/**
 * \brief OSP io vector type.
 *
 * \see OSP_PutV, OSP_GetV, OSP_PutAccV
 *
 * \ingroup TYPEDEFS
 *
 */

typedef struct OSP_iov_t
{
    void **source_ptr_ar;
    void **target_ptr_ar;
    int size; /*In bytes*/
    int ptr_ar_len;
} OSP_iov_t;

/* ********************************************************************* */
/*                                                                       */
/*               OSP external API - Helper Functions                      */
/*                                                                       */
/* ********************************************************************* */

/**
 * \brief Timer in units of cycles.
 *
 * \warning This function is not guaranteed to produce correct results for
 *          arbitrarily-long durations (e.g. in the case where the underlying
 *          cycle-accurate counter outputs a 32-bit integer).
 *
 * \param[out] rc   Number of cpu clock cycles from an arbitrary time in the past.
 *
 * \see OSP_Time_seconds
 *
 * \ingroup INFORMATION
 */

unsigned long long OSP_Time_cycles(void);

/**
 * \brief Timer in units of seconds.
 *
 *
 * \param[out] rc   Number of seconds from an arbitrary time in the past.
 *
 * \see OSP_Time_cycles
 *
 * \ingroup INFORMATION
 */

double OSP_Time_seconds(void);

/* ********************************************************************* */
/*                                                                       */
/*               OSP external API - Process Information                   */
/*                                                                       */
/* ********************************************************************* */

/**
 * \brief Returns process rank relative to the group base of the process calling it,
 *        or -1 in the case of an error.
 *
 * \note Jeff hates MPI-style function style where return value is an
 *       argument passed by reference for the sake of Fortran compatibility
 *       (or whatever their reason is).
 *
 * \see OSP_Node_id, OSP_Process_total
 *
 * \ingroup INFORMATION
 */

int OSP_Process_id(OSP_group_t* group);

/**
 * \brief Returns total number of processes in a group or -1 in the case of an error.
 *
 * \note Jeff hates MPI-style function style where return value is an
 *       argument passed by reference for the sake of Fortran compatibility
 *       (or whatever their reason is).
 *
 * \see OSP_Process_id, OSP_Node_total
 *
 * \ingroup INFORMATION
 */

int OSP_Process_total(OSP_group_t* group);

/**
 * \brief Returns node rank relative to the group base of the process calling it,
 *        or -1 in the case of an error.
 *
 * \note Jeff hates MPI-style function style where return value is an argument
 *       passed by reference for the sake of Fortran compatibility.
 *
 * \see OSP_Process_id, OSP_Node_total
 *
 * \ingroup INFORMATION
 */

int OSP_Node_id(OSP_group_t* group);

/**
 * \brief Returns total number of nodes in a group, or -1 in the case of an error.
 *
 * \note Jeff hates MPI-style function style where return value is an argument
 *       passed by reference for the sake of Fortran compatibility.
 *
 * \see OSP_Node_id, OSP_Process_total
 *
 * \ingroup INFORMATION
 */

int OSP_Node_total(OSP_group_t* group);

/* ********************************************************************* */
/*                                                                       */
/*               OSP external API - management                            */
/*                                                                       */
/* ********************************************************************* */

/**
 * \brief Initializes the Al environment.
 *
 * \warning If the MPID device is used, one should be careful in using OSP_Initialize and MPI_Init/MPI_Init_thread.
 *
 * \note Unlike MPI, OSP_Initialize may be called many times and but is not thread-safe.
 *       Improper use of OSP_Initialize (calling it more than once) shall be
 *       indicated by a non-zero error code and potentially warnings in
 *       stderr.
 *
 * \note Implementation detail: we need global variable indicated where or not
 *       OSP is alive or not to make this function thread-safe.
 *
 * \note This routine is called OSP_Initialize for syntactic symmetry with
 *       OSP_Finalize and because of Jeff's schadenfreude toward Pavan.
 *
 * \param[out] rc               The error code from initializing OSP
 * \param[in]  OSP_thread_level  The type of thread support for OSP
 *
 * \see OSP_thread_level
 *
 * \ingroup MANAGEMENT
 */

int OSP_Initialize(int OSP_thread_level);

/**
 * \brief Terminates the OSP environment normally.
 *
 * \warning If the MPID device is used, one should be careful in using OSP_Finalize and MPI_Finalize.
 *
 * \note Unlike MPI, OSP_Finalize may be called many times and is thread-safe.
 *       Improper use of OSP_Finalize (calling it more than once) shall be
 *       indicated by a non-zero error code and potentially warnings in
 *       stderr.
 *
 * \note Implementation detail: we need global variable indicated where or not
 *       OSP is alive or not to make this function thread-safe.
 *
 * \param[out] rc    The error code from terminating OSP.
 *
 * \see OSP_Initialize, OSP_Abort
 *
 * \ingroup MANAGEMENT
 */

int OSP_Finalize(void);

/**
 * \brief Terminates the OSP environment abnormally.
 *
 * \warning This must be the last OSP call made in any code unless OSP_Finalize is called instead.
 *
 * \param[in]  error_code    The error code to be returned to the submitting environment.
 * \param[in]  error_message Text string to print to stderr upon termination.
 *
 * \see OSP_Initialize, OSP_Finalize
 *
 * \ingroup MANAGEMENT
 */

void OSP_Abort(int error_code, char error_message[]);

/* ********************************************************************* */
/*                                                                       */
/*               OSP external API - memory                                */
/*                                                                       */
/* ********************************************************************* */

/**
 * \brief A local operation to allocate memory to be used in context of OSP copy operations.
 *
 * \note Memory allocated with this function will be properly aligned for the architecture.
 *
 * \warning Memory allocated with this function must be freed by OSP_Free_segment.
 *
 * \param[out] rc            The error code.
 * \param[out] ptr           Pointer to memregion structure to be created.
 * \param[in]  bytes         The amount of memory requested.
 *
 * \see OSP_Free_memregion, OSP_Bind_memregion
 *
 * \ingroup MEMORY
 */

int OSP_Allocate_memregion(OSP_memregion_t* memregion, int bytes);

/**
 * \brief A local operation to free memory allocated by OSP_Alloc_segment.
 *
 * \warning It is erroneous to attempt to free memory not allocated by OSP_Alloc_segment.
 *
 * \param[out] rc            The error code.
 * \param[in]  memregion     Pointer to memregion structure to be destroyed.
 *
 * \see OSP_Alloc_segment, OSP_Register_segment
 *
 * \ingroup MEMORY
 */

int OSP_Free_memregion(OSP_memregion_t* memregion);

/**
 * \brief A local operation to register memory to be used in context of OSP copy operations.
 *
 * \note This call is not necessary for memory allocated with OSP_Alloc_segment.
 *
 * \note Memory allocated with this function will be tested for proper alignment and return
 *       an error if alignment checking has been disabled and the pointer is not properly aligned.
 *
 * \note OSP_Register_segment will check for valid allocation of the memory provided,
 *       potentially by writing "\0" to all bytes.
 *
 * \note This call may not work in all contexts.  For example, CUDA provides no API call to
 *       register pre-allocated memory.  A truly portable OSP program must not call this
 *       function.
 *
 * \note We can make this call portable if we copy the existing data into the memregion
 *       and free the original buffer, but this is going to have nasty side-effects
 *       if the user doesn't realize this is what is going on.
 *
 * \param[out] rc            The error code.
 * \param[in]  ptr           Pointer to memregion structure to be created.
 * \param[in]  ptr           Pointer to previously-allocated memory.
 * \param[in]  bytes         The amount of memory provided.
 *
 * \see OSP_Alloc_segment, OSP_Free_segment
 *
 * \ingroup MEMORY
 */

int OSP_Bind_memregion(OSP_memregion_t* memregion, void** pointer, int bytes);

/**
 * \brief A collective operation to exchange addresses of segments to be used in context of OSP copy operations.
 *
 * \note There is no local de-registration call because that could lead to erroneous programs.
 *       De-registration can only be effected by a call to OSP_Release_segments, which is collective.
 *
 * \param[out] rc            The error code.
 * \param[in]  group         Group of processes within which the pointer list is exchanged.
 * \param[in]  ptr           Pointer array. Each one points to memory allocated at one process, in order of ranks.
 * \param[in]  bytes         The size of memory allocated at each process.
 *
 * \see OSP_Release_segments
 *
 * \ingroup MEMORY
 */

/* TODO: We should just implement alltoall and eliminate this function from the API. */
int OSP_Exchange_memregions(OSP_group_t* group, void **ptr);

/**
 * \brief A collective operation to invalidate and de-register memory segments
 *        associated with an OSP_Exchange_segments call.
 *
 * \param[out] rc            The error code.
 * \param[in]  group         Group of processes within which the pointer list was exchanged.
 * \param[in]  ptr           Pointer to the allocated memory.
 *
 * \see OSP_Exchange_segments
 *
 * \ingroup MEMORY
 */

/**
 * \brief Initializes the give non-blocking handle.
 *
 * \param[in] handle      Non-blocking handle upon which to be waited.
 *
 * \see OSP_handle_t, OSP_Wait_handle_list, OSP_Test_handle
 *
 * \ingroup MEMORY
 */

int OSP_Allocate_handle(OSP_handle_t *handle);

/**
 * \brief Initializes the give non-blocking handle.
 *
 * \param[in] handle      Non-blocking handle upon which to be waited.
 *
 * \see OSP_handle_t, OSP_Wait_handle_list, OSP_Test_handle
 *
 * \ingroup MEMORY
 */

int OSP_Release_handle(OSP_handle_t handle);

/**************************************************************************************/
/*    WARNING: THIS PART OF THE API IS DEPRECATED AND WILL BE REMOVED EVENTUALLY      */
/**************************************************************************************/

/**
 * \brief A local operation to allocate memory to be used in context of OSP copy operations.
 *
 * \note Memory allocated with this function will be properly aligned for the architecture.
 *
 * \warning Memory allocated with this function must be freed by OSP_Free_segment.
 *
 * \param[out] rc            The error code.
 * \param[out] ptr           Pointer to memory.
 * \param[in]  bytes         The amount of memory requested.
 *
 * \see OSP_Free_segment, OSP_Register_segment
 *
 * \ingroup MEMORY
 */

int OSP_Alloc_segment(void** pointer, int bytes);

/**
 * \brief A local operation to free memory allocated by OSP_Alloc_segment.
 *
 * \warning It is erroneous to attempt to free memory not allocated by OSP_Alloc_segment.
 *
 * \param[out] rc            The error code.
 * \param[in] ptr           Pointer to memory.
 *
 * \see OSP_Alloc_segment, OSP_Register_segment
 *
 * \ingroup MEMORY
 */

int OSP_Free_segment(void* pointer);

/**
 * \brief A local operation to register memory to be used in context of OSP copy operations.
 *
 * \note This call is not necessary for memory allocated with OSP_Alloc_segment.
 *
 * \note Memory allocated with this function will be tested for proper alignment and return
 *       an error if alignment checking has been disabled and the pointer is not properly aligned.
 *
 * \note OSP_Register_segment will check for valid allocation of the memory provided,
 *       potentially by writing "\0" to all bytes.
 *
 * \note This call may not work in all contexts.  For example, CUDA provides no API call to
 *       register pre-allocated memory.  A truly portable OSP program must not call this
 *       function.
 *
 * \param[out] rc            The error code.
 * \param[in]  ptr           Pointer to memory.
 * \param[in]  bytes         The amount of memory provided.
 *
 * \see OSP_Alloc_segment, OSP_Free_segment
 *
 * \ingroup MEMORY
 */

int OSP_Register_segment(void** pointer, int bytes);

/**
 * \brief A collective operation to exchange addresses of segments to be used in context of OSP copy operations.
 *
 * \note There is no local de-registration call because that could lead to erroneous programs.
 *       De-registration can only be effected by a call to OSP_Release_segments, which is collective.
 *
 * \param[out] rc            The error code.
 * \param[in]  group         Group of processes within which the pointer list is exchanged.
 * \param[in]  ptr           Pointer array. Each one points to memory allocated at one process, in order of ranks.
 * \param[in]  bytes         The size of memory allocated at each process.
 *
 * \see OSP_Release_segments
 *
 * \ingroup MEMORY
 */

/* TODO: We should just implement alltoall and eliminate this function from the API. */
int OSP_Exchange_segments(OSP_group_t* group, void **ptr);

/**
 * \brief A collective operation to invalidate and de-register memory segments
 *        associated with an OSP_Exchange_segments call.
 *
 * \param[out] rc            The error code.
 * \param[in]  group         Group of processes within which the pointer list was exchanged.
 * \param[in]  ptr           Pointer to the allocated memory.
 *
 * \see OSP_Exchange_segments
 *
 * \ingroup MEMORY
 */

/* TODO: I'm not sure this function is required.  One can get this functionality
 *        by having all processes free their segments and then calling a barrier. */
int OSP_Release_segments(OSP_group_t* group, void* ptr);

/* ********************************************************************** */
/*                                                                        */
/*               OSP external API - atomic operations                      */
/*                                                                        */
/* ********************************************************************** */

/**
 * \brief Collective operation to allocate and register a counter.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the counter is shared.
 * \param[inout]  counter       OSP shared counter.
 *
 * \see osp_counter_t, OSP_Destroy_counter, OSP_Incr_counter
 *
 * \ingroup Atomics
 */

int OSP_Create_counter(OSP_group_t* group, OSP_counter_t *counter);

/**
 * \brief Collective operation to deallocate and deregister a counter.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the counter is shared.
 * \param[inout]  counter       OSP shared counter.
 *
 * \see osp_counter_t, OSP_Create_counter, OSP_Incr_counter, OSP_NbIncr_counter
 *
 * \ingroup Atomics
 */

int OSP_Destroy_counter(OSP_group_t* group, OSP_counter_t *counter);

/* TODO: Does PPC32 (or 32-bit processors in general) support hardware atomics for 64-bit integers???
 *       I would like to use int64_t on all platforms if we can use them on Blue Gene/P.
 */

/**
 * \brief Atomically updates a shared counter and returns the current value.
 *
 * \param[out] rc            The error code.
 * \param[in]  counter       OSP shared counter.
 * \param[in]  increment     The value to add to the counter.
 * \param[in]  original      The remote value of the counter prior to the increment.
 *
 * \see osp_counter_t, OSP_Create_counter, OSP_Destroy_counter, OSP_NbIncr_counter
 *
 * \ingroup Atomics
 */

int OSP_Incr_counter(OSP_counter_t counter, long increment, long* original);

/**
 * \brief Non-blocking atomic RMW update of a shared counter.
 *
 * \param[out] rc            The error code.
 * \param[in]  counter       OSP shared counter.
 * \param[in]  increment     The value to add to the counter.
 * \param[in]  original      The remote value of the counter prior to the increment.
 * \param[out] handle        Opaque handle for the request
 *
 * \see osp_counter_t, OSP_Create_counter, OSP_Destroy_counter, OSP_Incr_counter
 *
 * \ingroup Atomics
 */

int OSP_NbIncr_counter(OSP_counter_t counter,
                      long* increment,
                      long* original,
                      OSP_handle_t handle);

/**
 * \brief Collective operation to allocate and register a list of mutexes.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the mutexes are shared.
 * \param[in]     count         Number of mutexes to be created.
 * \param[int]    count_ar      An arrays storing the number of mutexes on each process
 *
 * \see osp_mutex_t, OSP_Destroy_mutexes, OSP_Lock_mutex, OSP_Trylock_mutex, OSP_Unlock_mutex
 *
 * \ingroup Atomics
 */

int OSP_Create_mutexes(OSP_group_t* group, int mutex_count, int *mutex_count_ar);

/**
 * \brief Collective operation to deallocate and deregister a list of mutexes
 *
 * \note Implementors: OSP_mutex_t cannot be dynamically allocated otherwise this function
 *                     will create a memory leak.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the mutexes are shared.
 * \param[in]     mutexes       Pointer to vector OSP mutexes.
 *
 * \see osp_mutex_t, OSP_Create_mutexes, OSP_Lock_mutex, OSP_Trylock_mutex, OSP_Unlock_mutex
 *
 * \ingroup Atomics
 */

int OSP_Destroy_mutexes(OSP_group_t* group);

/**
 * \brief Local operation to lock a mutex.  This call blocks until the mutex has been locked.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the mutexes are shared.
 * \param[in]     mutex         OSP mutex.
 * \param[in]     proc          Process on which you want to lock mutex on
 *
 * \see osp_mutex_t, OSP_Trylock_mutex, OSP_Unlock_mutex, OSP_Create_mutexes, OSP_Destroy_mutex, OSP_Trylock_mutex, OSP_Unlock_mutex
 *
 * \ingroup Atomics
 */

int OSP_Lock_mutex(OSP_group_t* group, int mutex, int proc);

/**
 * \brief Local operation to trylock a mutex.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the mutexes are shared.
 * \param[in]     mutex         OSP mutex.
 * \param[in]     proc          Process on which you want to lock mutex on
 *
 * \see osp_mutex_t, OSP_Lock_mutex, OSP_Unlock_mutex, OSP_Create_mutexes, OSP_Destroy_mutex, OSP_Trylock_mutex, OSP_Unlock_mutex
 *
 * \ingroup Atomics
 */

int OSP_Trylock_mutex(OSP_group_t* group, int mutex, int proc, OSP_bool_t *acquired);

/**
 * \brief Local operation to unlock a mutex.  This call blocks until the mutex has been unlocked.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the mutexes are shared.
 * \param[in]     mutex         OSP mutex.
 * \param[in]     proc          Process on which you want to lock mutex on
 *
 * \see osp_mutex_t, OSP_Lock_mutex, OSP_Trylock_mutex, OSP_Create_mutexes, OSP_Destroy_mutex, OSP_Trylock_mutex, OSP_Unlock_mutex
 *
 * \ingroup Atomics
 */

int OSP_Unlock_mutex(OSP_group_t* group, int mutex, int proc);

/**
 * \brief Local operation to lock a list of mutexes.  This call blocks until ALL
 *        mutexes have been locked.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the mutexes are shared.
 * \param[in]     count         Number of mutexes to be locked.
 * \param[in]     mutexes       Pointer to vector OSP mutexes.
 * \param[in]     proc          Pointer to vector or process ranks.
 *
 * \see osp_mutex_t, OSP_Create_mutexes, OSP_Destroy_mutex, OSP_Trylock_mutex, OSP_Unlock_mutex
 *
 * \ingroup Atomics
 */

int OSP_Lock_mutexes(OSP_group_t* group, unsigned count, int *mutexes, int *procs);

/**
 * \brief Local operation to trylock a list of mutexes.  This call attempts to acquire all the
 *        locks given and sets the value of the corresponding offset in a vector of booleans
 *        indicating if the lock was acquired or not.
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the mutexes are shared.
 * \param[in]     count         Number of mutexes to be locked.
 * \param[in]     mutexes       Pointer to vector OSP mutexes.
 * \param[inout]  acquired      Pointer to vector OSP booleans indicating if the lock was acquired.
 *
 * \see osp_mutex_t, OSP_Create_mutexes, OSP_Destroy_mutex, OSP_Trylock_mutex, OSP_Unlock_mutex
 *
 * \ingroup Atomics
 */

int OSP_Trylock_mutexes(OSP_group_t* group, unsigned count, int *mutexes, int *procs, OSP_bool_t* *acquired);

/**
 * \brief Local operation to unlock a list of mutexes
 *
 * \param[out]    rc            The error code.
 * \param[in]     group         OSP group over which the mutexes are shared.
 * \param[in]     count         Number of mutexes to be locked.
 * \param[in]     mutexes       Pointer to vector OSP mutexes.
 *
 * \see osp_mutex_t, OSP_Create_mutexes, OSP_Destroy_mutex, OSP_Trylock_mutex, OSP_Unlock_mutex
 *
 * \ingroup Atomics
 */

int OSP_Unlock_mutexes(OSP_group_t* group, unsigned count, int *mutexes, int *procs);

/* FIXME: More API functions to come */

/* ********************************************************************** */
/*                                                                        */
/*               OSP external API - data transfer operations               */
/*                                                                        */
/* ********************************************************************** */

/**************************************************************************************/
/*    WARNING: THIS IS THE NEW API AND IS NOT YET IMPLEMENTED                         */
/**************************************************************************************/
/**
 * \brief Blocking copy of contiguous data from local memory to remote memory.
 *
 * \param[out] rc               The error code.
 * \param[in]  target           Rank of the remote endpoint.
 * \param[in]  source_mr        Source (local) memory region.
 * \param[in]  source_offset    Offset into source (local) memory region.
 * \param[in]  target_mr        Target (remote) memory region.
 * \param[in]  target_offset    Offset into target (remote) memory region.
 * \param[in]  bytes            Amount of data to transfer in bytes.
 *
 * \see OSP_Put
 *
 * \ingroup DATA_TRANSFER
 */

/* int OSP_PutMR(OSP_endpoint_t target, */
/*             OSP_memregion_t* source_mr, */
/*             OSP_offset_t source_offset, */
/*             OSP_memregion_t* target_mr, */
/*             OSP_offset_t target_offset, */
/*             OSP_size_t bytes); */

/**************************************************************************************/
/*    WARNING: THIS PART OF THE API IS DEPRECATED AND WILL BE REMOVED EVENTUALLY      */
/**************************************************************************************/

/**
 * \brief Blocking copy of contiguous data from local memory to remote memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  target        Rank of the remote process.
 * \param[in]  source_ptr    Starting address in the (local) source memory.
 * \param[in]  target_ptr    Starting address in the (remote) target memory.
 * \param[in]  bytes         Amount of data to transfer in bytes.
 *
 * \see OSP_NbPut, OSP_MultiPut
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_Put(int target, void* source_ptr, void* target_ptr, int bytes);

/**
 * \brief Non-Blocking copy of contiguous data from local memory to remote memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  target        Rank of the remote process.
 * \param[in]  source_ptr    Starting address in the (local) source memory.
 * \param[in]  target_ptr    Starting address in the (remote) target memory.
 * \param[in]  bytes         Amount of data to transfer in bytes.
 * \param[out] handle        Opaque handle for the request
 *
 * \see OSP_Put, OSP_NbMultiPut
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbPut(int target,
             void* source_ptr,
             void* target_ptr,
             int bytes,
             OSP_handle_t handle);

/**
 * \brief Blocking copy of contiguous data from local memory to remote memory.
 *
 * \note OSP_MultiPut can be used for single-target non-contiguous put as well,
 *       but the implementation may be far from optimal relative to OSP_PutS
 *       and OSP_PutV.
 *
 * \param[out] rc            The error code.
 * \param[in]  count         Number of operations to be performed
 * \param[in]  targets       Vector of remote process ranks.
 * \param[in]  source_ptr    Vector of starting addresses in the (local) source memory.
 * \param[in]  target_ptr    Vector of starting addresses in the (remote) target memory.
 * \param[in]  bytes         Vector of quantity of data to transfer in bytes.
 *
 * \see OSP_Put
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_MultiPut(int count,
                int *targets,
                void* *source_ptr,
                void* *target_ptr,
                int *bytes);

/**
 * \brief Nonblocking copy of contiguous data from local memory to remote memory.
 *
 * \note OSP_MultiPut can be used for single-target non-contiguous put as well,
 *       but the implementation may be far from optimal relative to OSP_PutS
 *       and OSP_PutV.
 *
 * \param[out] rc            The error code.
 * \param[in]  count         Number of operations to be performed
 * \param[in]  targets       Vector of remote process ranks.
 * \param[in]  source_ptr    Vector of starting addresses in the (local) source memory.
 * \param[in]  target_ptr    Vector of starting addresses in the (remote) target memory.
 * \param[in]  bytes         Vector of quantity of data to transfer in bytes.
 *
 * \see OSP_NbPut, OSP_MultiPut
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbMultiPut(int count,
                  int *targets,
                  void* *source_ptr,
                  void* *target_ptr,
                  int *bytes,
                  OSP_handle_t handle);

/**
 * \brief Blocking copy of strided data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  count           Block size in each dimension in bytes.
 * \param[in]  stride_levels   The number of levels of stride.
 * \param[in]  source_ptr      Starting address in the (local) source memory.
 * \param[in]  src_stride_ar   Array of stride distances at source in bytes.
 * \param[in]  target_ptr      Starting address in the (remote) target memory.
 * \param[in]  trg_stride_ar   Array of stride distances at target in bytes.
 *
 * \see OSP_Put, OSP_PutV, OSP_MultiPut, OSP_MultiPutS, OSP_MultiPutV
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_PutS(int target,
            int stride_levels,
            int *block_sizes,
            void* source_ptr,
            int *src_stride_ar,
            void* target_ptr,
            int *trg_stride_ar);

/**
 * \brief Non-Blocking copy of strided data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  count           Block size in each dimension in bytes.
 * \param[in]  stride_levels   The number of levels of stride.
 * \param[in]  source_ptr      Starting address in the (local) source memory.
 * \param[in]  src_stride_ar   Array of stride distances at source in bytes.
 * \param[in]  target_ptr      Starting address in the (remote) target memory.
 * \param[in]  trg_stride_ar   Array of stride distances at target in bytes.
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_NbPut, OSP_NbPutV, OSP_NbMultiPut, OSP_NbMultiPutS, OSP_NbMultiPutV
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbPutS(int target,
              int stride_levels,
              int *block_sizes,
              void* source_ptr,
              int *src_stride_ar,
              void* target_ptr,
              int *trg_stride_ar,
              OSP_handle_t handle);

/**
 * \brief Blocking copy of contiguous data from local memory to remote memory.
 *
 * \note This call must be use the same stride-level across all targets.
 *
 * \param[out] rc              The error code.
 * \param[in]  count           Number of operations to be performed
 * \param[in]  targets         Vector of remote process ranks.
 * \param[in]  block_sizes     Vector of block sizes in each dimension in bytes.
 * \param[in]  stride_levels   Number of levels of stride.
 * \param[in]  source_ptr      Vector of starting in the (local) source memory.
 * \param[in]  src_stride_ar   Vector of arrays of stride distances at source in bytes.
 * \param[in]  target_ptr      Vector of starting in the (remote) target memory.
 * \param[in]  trg_stride_ar   Vector of arrays of stride distances at target in bytes.
 *
 * \see OSP_Put, OSP_Get, OSP_Copy, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_MultiPutS(int count,
                 int *targets,
                 int stride_levels,
                 int* *block_sizes,
                 void* source_ptr,
                 int *src_stride_ar,
                 void* target_ptr,
                 int *trg_stride_ar);

/**
 * \brief Nonblocking copy of contiguous data from local memory to remote memory.
 *
 * \note This call must be use the same stride-level across all targets.
 *
 * \param[out] rc              The error code.
 * \param[in]  count           Number of operations to be performed
 * \param[in]  targets         Vector of remote process ranks.
 * \param[in]  block_sizes     Vector of block sizes in each dimension in bytes.
 * \param[in]  stride_levels   Number of levels of stride.
 * \param[in]  source_ptr      Vector of starting in the (local) source memory.
 * \param[in]  src_stride_ar   Vector of arrays of stride distances at source in bytes.
 * \param[in]  target_ptr      Vector of starting in the (remote) target memory.
 * \param[in]  trg_stride_ar   Vector of arrays of stride distances at target in bytes.
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_Put, OSP_Get, OSP_Copy, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbMultiPutS(int count,
                   int *targets,
                   int stride_levels,
                   int* *block_sizes,
                   void* source_ptr,
                   int *src_stride_ar,
                   void* target_ptr,
                   int *trg_stride_ar,
                   OSP_handle_t handle);

/**
 * \brief Blocking copy of non-contiguous data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  iov_ar          Array of io vectors. Each vector represents a set of chunks of same size.
 * \param[in]  ar_len          Number of elements in the array.
 *
 * \see OSP_NbPut, OSP_NbPutV, OSP_NbMultiPut, OSP_NbMultiPutS, OSP_NbMultiPutV
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_PutV(int target, OSP_iov_t *iov_ar, int ar_len);

/**
 * \brief Non-Blocking copy of non-contiguous data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  iov_ar          Array of io vectors. Each vector represents a set of chunks of same size.
 * \param[in]  ar_len          Number of elements in the array.
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_NbPut, OSP_NbPutV, OSP_NbMultiPut, OSP_NbMultiPutS, OSP_NbMultiPutV
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbPutV(int target, OSP_iov_t *iov_ar, int ar_len, OSP_handle_t handle);

/**
 * \brief Blocking accumulate of contiguous data from local memory onto remote memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  target        Rank of the remote process.
 * \param[in]  source_ptr    Starting address in the (local) source memory.
 * \param[in]  target_ptr    Starting address in the (remote) target memory.
 * \param[in]  bytes         Amount of data to transfer in bytes.
 * \param[in]  osp_type       Datatype of buffer and scaling factor.
 * \param[in]  scaling       Factor for scaling source.
 *
 * \see OSP_Put, OSP_Copy, OSP_CopyAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_PutAcc(int target,
              void* source_ptr,
              void* target_ptr,
              int bytes,
              OSP_datatype_t osp_type,
              void* scaling);

/**
 * \brief Non-Blocking accumulate of contiguous data from local memory onto remote memory.
 * 
 * \param[out] rc            The error code.
 * \param[in]  target        Rank of the remote process.
 * \param[in]  source_ptr    Starting address in the (local) source memory.
 * \param[in]  target_ptr    Starting address in the (remote) target memory.
 * \param[in]  bytes         Amount of data to transfer in bytes.
 * \param[in]  osp_type       Datatype of buffer and scaling factor.
 * \param[in]  scaling       Factor for scaling source
 * \param[out] handle        Opaque OSP handle 
 *
 * \see OSP_Put, OSP_Copy, OSP_CopyAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbPutAcc(int target,
                void* source_ptr,
                void* target_ptr,
                int bytes,
                OSP_datatype_t osp_type,
                void* scaling,
                OSP_handle_t handle);

/**
 * \brief Blocking accumulate of contiguous data from local memory to remote memory.
 *
 * \note OSP_MultiPut can be used for single-target non-contiguous put as well,
 *       but the implementation may be far from optimal relative to OSP_PutS
 *       and OSP_PutV.
 *
 * \param[out] rc            The error code.
 * \param[in]  count         Number of operations to be performed
 * \param[in]  targets       Vector of remote process ranks.
 * \param[in]  source_ptr    Vector of starting addresses in the (local) source memory.
 * \param[in]  target_ptr    Vector of starting addresses in the (remote) target memory.
 * \param[in]  bytes         Vector of quantity of data to transfer in bytes.
 * \param[in]  osp_type       Datatype of buffer and scaling factor.
 * \param[in]  scaling       Factor for scaling source.
 *
 * \see OSP_Put
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_MultiPutAcc(int count,
                   int *targets,
                   void* *source_ptr,
                   void* *target_ptr,
                   int *bytes,
                   OSP_datatype_t osp_type,
                   void* scaling);

/**
 * \brief Nonblocking accumulate of contiguous data from local memory to remote memory.
 *
 * \note OSP_MultiPut can be used for single-target non-contiguous put as well,
 *       but the implementation may be far from optimal relative to OSP_PutS
 *       and OSP_PutV.
 *
 * \param[out] rc            The error code.
 * \param[in]  count         Number of operations to be performed
 * \param[in]  targets       Vector of remote process ranks.
 * \param[in]  source_ptr    Vector of starting addresses in the (local) source memory.
 * \param[in]  target_ptr    Vector of starting addresses in the (remote) target memory.
 * \param[in]  bytes         Vector of quantity of data to transfer in bytes.
 * \param[in]  osp_type       Datatype of buffer and scaling factor.
 * \param[in]  scaling       Factor for scaling source.
 * \param[out] handle        Opaque OSP handle
 *
 * \see OSP_NbPut, OSP_MultiPut
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbMultiPutAcc(int count,
                     int *targets,
                     void* *source_ptr,
                     void* *target_ptr,
                     int *bytes,
                     OSP_datatype_t osp_type,
                     void* scaling,
                     OSP_handle_t handle);

/**
 * \brief Blocking accumulate of strided data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  stride_levels   The number of levels of stride.
 * \param[in]  block_sizes     Block size in each dimension in bytes.
 * \param[in]  source_ptr      Starting address in the (local) source memory.
 * \param[in]  src_stride_ar   Array of stride distances at source in bytes.
 * \param[in]  target_ptr      Starting address in the (remote) target memory.
 * \param[in]  trg_stride_ar   Array of stride distances at target in bytes.
 * \param[in]  osp_type         Type of data and scaling factor
 * \param[in]  *scaling        Scaling factor in the accumulate operation. 
 *
 * \see OSP_Put, OSP_PutS, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_PutAccS(int target,
               int stride_levels,
               int *block_sizes,
               void* source_ptr,
               int *src_stride_ar,
               void* target_ptr,
               int *trg_stride_ar,
               OSP_datatype_t osp_type,
               void* scaling);

/**
 * \brief Non-Blocking accumulate of strided data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  stride_levels   The number of levels of stride.
 * \param[in]  block_sizes     Block size in each dimension in bytes.
 * \param[in]  source_ptr      Starting address in the (local) source memory.
 * \param[in]  src_stride_ar   Array of stride distances at source in bytes.
 * \param[in]  target_ptr      Starting address in the (remote) target memory.
 * \param[in]  trg_stride_ar   Array of stride distances at target in bytes.
 * \param[in]  osp_type         Type of data and scaling factor
 * \param[in]  *scaling        Scaling factor in the accumulate operation. 
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_Put, OSP_PutS, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbPutAccS(int target,
                 int stride_levels,
                 int *block_sizes,
                 void* source_ptr,
                 int *src_stride_ar,
                 void* target_ptr,
                 int *trg_stride_ar,
                 OSP_datatype_t osp_type,
                 void* scaling,
                 OSP_handle_t handle);

/**
 * \brief Blocking copy of contiguous data from local memory to remote memory.
 *
 * \note This call must be use the same stride-level across all targets.
 *
 * \param[out] rc              The error code.
 * \param[in]  count           Number of operations to be performed
 * \param[in]  targets         Vector of remote process ranks.
 * \param[in]  block_sizes     Vector of block sizes in each dimension in bytes.
 * \param[in]  stride_levels   Number of levels of stride.
 * \param[in]  source_ptr      Vector of starting in the (local) source memory.
 * \param[in]  src_stride_ar   Vector of arrays of stride distances at source in bytes.
 * \param[in]  target_ptr      Vector of starting in the (remote) target memory.
 * \param[in]  trg_stride_ar   Vector of arrays of stride distances at target in bytes.
 * \param[in]  osp_type         Type of data and scaling factor
 * \param[in]  *scaling        Scaling factor in the accumulate operation.
 *
 * \see OSP_Put, OSP_Get, OSP_Copy, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_MultiPutAccS(int count,
                    int *targets,
                    int stride_levels,
                    int* *block_sizes,
                    void* source_ptr,
                    int *src_stride_ar,
                    void* target_ptr,
                    int *trg_stride_ar,
                    OSP_datatype_t osp_type,
                    void* scaling);

/**
 * \brief Nonblocking copy of contiguous data from local memory to remote memory.
 *
 * \note This call must be use the same stride-level across all targets.
 *
 * \param[out] rc              The error code.
 * \param[in]  count           Number of operations to be performed
 * \param[in]  targets         Vector of remote process ranks.
 * \param[in]  block_sizes     Vector of block sizes in each dimension in bytes.
 * \param[in]  stride_levels   Number of levels of stride.
 * \param[in]  source_ptr      Vector of starting in the (local) source memory.
 * \param[in]  src_stride_ar   Vector of arrays of stride distances at source in bytes.
 * \param[in]  target_ptr      Vector of starting in the (remote) target memory.
 * \param[in]  trg_stride_ar   Vector of arrays of stride distances at target in bytes.
 * \param[in]  osp_type         Type of data and scaling factor
 * \param[in]  *scaling        Scaling factor in the accumulate operation.
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_Put, OSP_Get, OSP_Copy, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbMultiPutAccS(int count,
                      int *targets,
                      int stride_levels,
                      int* *block_sizes,
                      void* source_ptr,
                      int *src_stride_ar,
                      void* target_ptr,
                      int *trg_stride_ar,
                      OSP_datatype_t osp_type,
                      void* scaling,
                      OSP_handle_t handle);

/**
 * \brief Blocking accumulate of non-contiguous data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  iov_ar          Array of io vectors. Each vector represents a set of
 *                             chunks of same size.
 * \param[in]  ar_len          Number of elements in the array.
 * \param[in]  osp_type         Type of data and scaling factor
 * \param[in]  *scaling        Scaling factor in the accumulate operation. 
 * 
 * \see OSP_NbPut, OSP_NbPutV, OSP_NbMultiPut, OSP_NbMultiPutS, OSP_NbMultiPutV
 * 
 * \ingroup DATA_TRANSFER
 */

int OSP_PutAccV(int target,
               OSP_iov_t *iov_ar,
               int ar_len,
               OSP_datatype_t osp_type,
               void* scaling);

/**
 * \brief Non-Blocking accumulate of non-contiguous data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  iov_ar          Array of io vectors. Each vector represents a set of
 *                             chunks of same size.
 * \param[in]  ar_len          Number of elements in the array.
 * \param[in]  osp_type         Type of data and scaling factor
 * \param[in]  *scaling        Scaling factor in the accumulate operation.
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_NbPut, OSP_NbPutV, OSP_NbMultiPut, OSP_NbMultiPutS, OSP_NbMultiPutV
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbPutAccV(int target,
                 OSP_iov_t *iov_ar,
                 int ar_len,
                 OSP_datatype_t osp_type,
                 void* scaling,
                 OSP_handle_t handle);

/**
 * \brief Blocking remote modify of non-contiguous data from local memory to remote memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  iov_ar          Array of io vectors. Each vector represents a set of
 *                             chunks of same size.
 * \param[in]  ar_len          Number of elements in the array.
 * \param[in]  osp_op           Reduce operation
 * \param[in]  osp_type         Type of data and scaling factor
 *
 * \see OSP_NbPut, OSP_NbPutV, OSP_NbMultiPut, OSP_NbMultiPutS, OSP_NbMultiPutV
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_PutModV(int target,
               OSP_iov_t *iov_ar,
               int ar_len,
               OSP_reduce_op_t osp_op,
               OSP_datatype_t osp_type);

/**
 * \brief Blocking copy of contiguous data from remote memory to local memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  target        Rank of the remote process.
 * \param[in]  source_ptr    Starting address in the (remote) source memory.
 * \param[in]  target_ptr    Starting address in the (local) target memory.
 * \param[in]  bytes         Amount of data to transfer in bytes.
 *
 * \see OSP_NbGet, OSP_Put, OSP_Copy
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_Get(int target, void* source_ptr, void* target_ptr, int bytes);

/**
 * \brief Non-Blocking copy of contiguous data from remote memory to local memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  target        Rank of the remote process.
 * \param[in]  source_ptr    Starting address in the (remote) source memory.
 * \param[in]  target_ptr    Starting address in the (local) target memory.
 * \param[in]  bytes         Amount of data to transfer in bytes.
 * \param[out] handle        Opaque handle for the request
 *
 * \see OSP_Get, OSP_Put, OSP_Copy
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbGet(int target,
             void* source_ptr,
             void* target_ptr,
             int bytes,
             OSP_handle_t handle);

/**
 * \brief Blocking copy of contiguous data from remote memory onto local memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  count         Number of operations to be performed
 * \param[in]  target        Vector of remote process ranks.
 * \param[in]  source_ptr    Vector of starting address in the (remote) source memory.
 * \param[in]  target_ptr    Vector of starting address in the (local) target memory.
 * \param[in]  bytes         Vector of data to transfer from each target in bytes.
 *
 * \see OSP_Get, OSP_MultiPut, OSP_Copy
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_MultiGet(int count,
                int *target,
                void* *source_ptr,
                void* *target_ptr,
                int *bytes);

/**
 * \brief Nonblocking copy of contiguous data from remote memory onto local memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  count         Number of operations to be performed
 * \param[in]  target        Vector of remote process ranks.
 * \param[in]  source_ptr    Vector of starting address in the (remote) source memory.
 * \param[in]  target_ptr    Vector of starting address in the (local) target memory.
 * \param[in]  bytes         Vector of data to transfer from each target in bytes.
 * \param[out] handle        Opaque OSP handle
 *
 * \see OSP_Get, OSP_MultiPut, OSP_Copy
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbMultiGet(int count,
                  int *target,
                  void* *source_ptr,
                  void* *target_ptr,
                  int *bytes,
                  OSP_handle_t handle);

/**
 * \brief Blocking copy of strided data from remote memory to local memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  source_ptr      Starting address in the (remote) source memory.
 * \param[in]  src_stride_ar   Array of stride distances at (remote process) source in bytes.
 * \param[in]  target_ptr      Starting address in the (local) target memory.
 * \param[in]  trg_stride_ar   Array of stride distances at (local process) target in bytes.
 * \param[in]  count           Block size in each dimension in bytes.
 * \param[in]  stride_levels   The number of levels of stride.
 *
 * \see OSP_Put, OSP_Get, OSP_Copy, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_GetS(int target,
            int stride_levels,
            int *block_sizes,
            void* source_ptr,
            int *src_stride_ar,
            void* target_ptr,
            int *trg_stride_ar);

/**
 * \brief Non-Blocking copy of strided data from remote memory to local memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  source_ptr      Starting address in the (remote) source memory.
 * \param[in]  src_stride_ar   Array of stride distances at (remote process) source in bytes.
 * \param[in]  target_ptr      Starting address in the (local) target memory.
 * \param[in]  trg_stride_ar   Array of stride distances at (local process) target in bytes.
 * \param[in]  count           Block size in each dimension in bytes.
 * \param[in]  stride_levels   The number of levels of stride.
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_Put, OSP_Get, OSP_Copy, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbGetS(int target,
              int stride_levels,
              int *block_sizes,
              void* source_ptr,
              int *src_stride_ar,
              void* target_ptr,
              int *trg_stride_ar,
              OSP_handle_t handle);

/**
 * \brief Blocking copy of stided data from remote memory to local memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  count           Number of operations to be performed
 * \param[in]  target          Rank of the remote process.
 * \param[in]  source_ptr      Starting address in the (remote) source memory.
 * \param[in]  src_stride_ar   Array of stride distances at (remote process) source in bytes.
 * \param[in]  target_ptr      Starting address in the (local) target memory.
 * \param[in]  trg_stride_ar   Array of stride distances at (local process) target in bytes.
 * \param[in]  count           Block size in each dimension in bytes.
 * \param[in]  stride_levels   The number of levels of stride.
 *
 * \see OSP_Put, OSP_Get, OSP_Copy, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_MultiGetS(int target_count,
                 int *target,
                 int stride_levels,
                 int **count,
                 void* *source_ptr,
                 int **src_stride_ar,
                 void* *target_ptr,
                 int **trg_stride_ar);

/**
 * \brief Blocking copy of stided data from remote memory to local memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  count           Number of operations to be performed
 * \param[in]  target          Rank of the remote process.
 * \param[in]  source_ptr      Starting address in the (remote) source memory.
 * \param[in]  src_stride_ar   Array of stride distances at (remote process) source in bytes.
 * \param[in]  target_ptr      Starting address in the (local) target memory.
 * \param[in]  trg_stride_ar   Array of stride distances at (local process) target in bytes.
 * \param[in]  count           Block size in each dimension in bytes.
 * \param[in]  stride_levels   The number of levels of stride.
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_Put, OSP_Get, OSP_Copy, OSP_PutAcc
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbMultiGetS(int target_count,
                   int *target,
                   int stride_levels,
                   int **count,
                   void* *source_ptr,
                   int **src_stride_ar,
                   void* *target_ptr,
                   int **trg_stride_ar,
                   OSP_handle_t handle);

/**
 * \brief Blocking copy of non-contiguous data from remote memory to local memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  iov_ar          Array of io vectors. Each vector represents a set of
 *                             chunks of same size.
 * \param[in]  ar_len          Number of elements in the array.
 *
 * \see OSP_NbPut, OSP_NbPutV, OSP_NbMultiPut, OSP_NbMultiPutS, OSP_NbMultiPutV
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_GetV(int target, OSP_iov_t *iov_ar, int ar_len);

/**
 * \brief Non-Blocking copy of non-contiguous data from remote memory to local memory.
 *
 * \param[out] rc              The error code.
 * \param[in]  target          Rank of the remote process.
 * \param[in]  iov_ar          Array of io vectors. Each vector represents a set of
 *                             chunks of same size.
 * \param[in]  ar_len          Number of elements in the array.
 * \param[out] handle          Opaque OSP handle
 *
 * \see OSP_NbPut, OSP_NbPutV, OSP_NbMultiPut, OSP_NbMultiPutS, OSP_NbMultiPutV
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbGetV(int target, OSP_iov_t *iov_ar, int ar_len, OSP_handle_t handle);

/**
 * \brief Blocking get-and-accumulate operation (aka RMW) on arbitrary data.
 *        This operation is message-wise atomic.
 *
 * \warning Obviously, the user cannot mix RMW with other operations without
 *          proper synchronization.
 *
 * \param[out] rc               The error code.
 * \param[in]  target           Rank of the target process.
 * \param[in]  source_ptr_in    Pointer of modification data at source process.
 * \param[in]  source_ptr_out   Pointer of original read data at source process.
 * \param[in]  target_ptr       Pointer of modified data at target process.
 * \param[in]  bytes            Number of bytes to update.
 * \param[in]  op               Operation to be performed.
 * \param[in]  osp_type          Type of data and value.
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_Rmw(int target,
           void* source_ptr_in,
           void* source_ptr_out,
           void* target_ptr,
           int bytes,
           OSP_atomic_op_t op,
           OSP_datatype_t osp_type);

/**
 * \brief Non-blocking get-and-accumulate operation (aka RMW) on arbitrary data.
 *        This operation is message-wise atomic.
 *
 * \warning Obviously, the user cannot mix RMW with other operations without
 *          proper synchronization.
 *
 * \param[out] rc               The error code.
 * \param[in]  target           Rank of the target process.
 * \param[in]  source_ptr_in    Pointer of modification data at source process.
 * \param[in]  source_ptr_out   Pointer of original read data at source process.
 * \param[in]  target_ptr       Pointer of modified data at target process.
 * \param[in]  bytes            Number of bytes to update.
 * \param[in]  op               Operation to be performed.
 * \param[in]  osp_type          Type of data and value.
 * \param[out] handle          Opaque OSP handle
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_NbRmw(int target,
             void* source_ptr_in,
             void* source_ptr_out,
             void* target_ptr,
             int bytes,
             OSP_atomic_op_t op,
             OSP_datatype_t osp_type,
             OSP_handle_t handle);

/**
 * \brief Blocking copy of contiguous data from remote memory to remote memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  source        Rank of the (remote) source process.
 * \param[in]  target        Rank of the (remote) target process.
 * \param[in]  source_ptr    Starting address in the (remote) source memory.
 * \param[in]  target_ptr    Starting address in the (remote) target memory.
 * \param[in]  bytes         Amount of data to transfer in bytes.
 *
 * \see OSP_Put, OSP_Get
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_Copy(int source,
            int target,
            void* source_ptr,
            void* target_ptr,
            int bytes);

/**
 * \brief Blocking accumulate of contiguous data from remote memory onto remote memory.
 *
 * \param[out] rc            The error code.
 * \param[in]  source        Rank of the (remote) source process.
 * \param[in]  target        Rank of the (remote) target process.
 * \param[in]  source_ptr    Starting address in the (remote) source memory.
 * \param[in]  target_ptr    Starting address in the (remote) target memory.
 * \param[in]  bytes         Amount of data to transfer in bytes.
 * \param[in]  osp_type       Amount of data to transfer in bytes.
 * \param[in]  scaling       Factor for scaling source
 *
 * \see OSP_Put, OSP_Get
 *
 * \ingroup DATA_TRANSFER
 */

int OSP_CopyAcc(int source,
               int target,
               void* source_ptr,
               void* target_ptr,
               int bytes,
               OSP_datatype_t osp_type,
               void* scaling);

/* FIXME: More API functions to come */

/* ********************************************************************** */
/*                                                                        */
/*               OSP external API - synchronization and completion         */
/*                                                                        */
/* ********************************************************************** */

/**
 * \brief On return, this call ensures that all processes within the entire group
 *        have reached this point in the program.
 *
 *        This operation is collective and blocking.
 *
 * \param[out] rc            The error code.
 * \param[in] group          Group of processes to synchronize.
 *
 * \see OSP_Flush, OSP_AllFlush, OSP_Sync.
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Barrier_group(OSP_group_t* group);

/**
 * \brief When the handle state is OSP_TRUE, all processes within the entire group
 *        have reached this point in the program.
 *
 *        This operation is collective and non-blocking.
 *
 * \param[out] rc            The error code.
 * \param[in] group          Group of processes to synchronize.
 *
 * \see OSP_Flush, OSP_AllFlush, OSP_Sync.
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_NbBarrier_group(OSP_group_t* group, OSP_handle_t handle);

/**
 * \brief On return, this call ensures that all outstanding put or accumulate
 *        operations are complete remotely within the entire group.
 *
 *        This operation is collective and blocking.  It has the effect of
 *        OSP_Flush_group called from every process in the group followed by OSP_Barrier_group.
 *
 * \param[out] rc            The error code.
 * \param[in] group          Group of processes to synchronize.
 *
 * \see OSP_GlobalSync, OSP_GroupBarrier, OSP_Flush_group.
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Sync_group(OSP_group_t* group);

/**
 * \brief When the handle state is OSP_TRUE, all outstanding put or accumulate
 *        operations are complete remotely within the entire group.
 *
 *        This operation is collective and blocking.  It has the effect of
 *        OSP_NbFlush_group called from every process in the group followed by OSP_NbBarrier_group.
 *
 * \param[out] rc            The error code.
 * \param[in] group          Group of processes to synchronize.
 *
 * \see OSP_GlobalSync, OSP_GroupBarrier, OSP_Flush_group.
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_NbSync_group(OSP_group_t* group, OSP_handle_t handle);

/**
 * \brief On return, this call ensures that all blocking and non-blocking put
 *        and accumulate operations sent to the target process have completed remotely.
 *
 *        This operation is local and blocking.
 *
 * \param[out] rc            The error code.
 * \param[in]  proc          Rank of the remote process.
 *
 * \see OSP_Flush_group, OSP_Sync
 *
 * \ingroup COMPLETION
 */

int OSP_Flush(int proc);

/**
 * \brief When the handle state is OSP_TRUE, all blocking and non-blocking put
 *        and accumulate operations sent to the target process have completed remotely.
 *
 *        This operation is local and non-blocking.
 *
 * \param[out] rc            The error code.
 * \param[in]  proc          Rank of the remote process.
 *
 * \see OSP_Flush_group, OSP_Sync
 *
 * \ingroup COMPLETION
 */

int OSP_NbFlush(int proc, OSP_handle_t handle);

/**
 * \brief On return, this call ensures that all blocking and non-blocking put
 *        and accumulate operations have completed remotely at the processes given in the list.
 *
 *        This operation is local and blocking.
 *
 * \param[out] rc                The error code.
 * \param[in] count              Number of processes in vector.
 * \param[in] proc_list          Vector of processes to flush against.
 *
 * \see OSP_Flush, OSP_Flush_group
 *
 * \ingroup COMPLETION
 */

int OSP_Flush_list(int count, int *proc_list);

/**
 * \brief When the handle state is OSP_TRUE, all blocking and non-blocking put
 *        and accumulate operations have completed remotely at the processes given in the list.
 *
 *        This operation is local and blocking.
 *
 * \param[out] rc                The error code.
 * \param[in] count              Number of processes in vector.
 * \param[in] proc_list          Vector of processes to flush against.
 *
 * \see OSP_Flush, OSP_Flush_group
 *
 * \ingroup COMPLETION
 */

int OSP_NbFlush_list(int count, int *proc_list, OSP_handle_t handle);

/**
 * \brief On return, this call ensures that all blocking and non-blocking put
 *        and accumulate operations have completed remotely at the processes in the group.
 *
 *        This operation is local and blocking.
 *
 * \param[out] rc                The error code.
 * \param[in] count              Number of processes in vector.
 * \param[in] proc_list          List of processes to flush against.
 *
 * \see OSP_Flush, OSP_Sync
 *
 * \ingroup COMPLETION
 */

int OSP_Flush_group(OSP_group_t* group);

/**
 * \brief When the handle state is OSP_TRUE, all blocking and non-blocking put
 *        and accumulate operations have completed remotely at the processes in the group.
 *
 *        This operation is local and blocking.
 *
 * \param[out] rc                The error code.
 * \param[in] count              Number of processes in vector.
 * \param[in] proc_list          List of processes to flush against.
 *
 * \see OSP_Flush, OSP_Sync
 *
 * \ingroup COMPLETION
 */

int OSP_NbFlush_group(OSP_group_t* group, OSP_handle_t handle);

/**
 * \brief Blocks on completion of all non-blocking handles.
 *
 * \param[out] rc                The error code.
 *
 * \see OSP_handle_t, OSP_Wait_handle_list, OSP_Test_handle
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Wait_handle_all(void);

/**
 * \brief Blocks on completion of a non-blocking handle.
 *
 * \param[in] handle      Non-blocking handle upon which to be waited.
 *
 * \see OSP_handle_t, OSP_Wait_handle_list, OSP_Test_handle
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Wait_handle(OSP_handle_t handle);

/**
 * \brief Blocks on completion of all elements in a vector of non-blocking handles.
 *
 * \param[in] count        Number of handles in vector.
 * \param[in] handles      Vector of non-blocking handles upon which to be waited.
 *
 * \see OSP_handle_t, OSP_Wait_handle, OSP_Test_handle_list
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Wait_handle_list(int count, OSP_handle_t* handles);

/**
 * \brief Blocks on completion of a non-blocking handle.
 *
 * \param[in]  handle        Non-blocking handle upon which to be waited.
 * \param[out] completed     Handle status.
 *
 * \see OSP_handle_t, OSP_Wait_handle, OSP_Test_handle_list
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Test_handle(OSP_handle_t handle, OSP_bool_t* completed);

/**
 * \brief Blocks on completion of all elements in a vector of non-blocking handles.
 *
 * \param[in]  count        Number of handles in vector.
 * \param[in]  handles      Vector of non-blocking handles upon which to be waited.
 * \param[out] completed    Vector of handle statuses.
 *
 * \see OSP_handle_t, OSP_Test_handle, OSP_Wait_handle_list
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Test_handle_list(int count, OSP_handle_t *handles, OSP_bool_t* *completed);

/**
 * \brief Resets a non-blocking handle.
 *
 * \param[in] handle      Non-blocking handle to be reset.
 *
 * \see OSP_handle_t, OSP_Reset_handle_list
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Reset_handle(OSP_handle_t* handle);

/**
 * \brief Resets a non-blocking handle.
 *
 * \param[in]  count        Number of handles in vector.
 * \param[in] handle      Non-blocking handle to be reset.
 *
 * \see OSP_handle_t, OSP_Reset_handle
 *
 * \ingroup SYNCHRONIZATION
 */

int OSP_Reset_handle_list(int count, OSP_handle_t* handle);

/* ********************************************************************** */
/*                                                                        */
/*               OSP external API - many-to-many operations                */
/*                                                                        */
/* ********************************************************************** */

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_Multicast_group(OSP_group_t* group,
                       int root,
                       int count,
                       OSP_datatype_t osp_type,
                       void* buffer);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_NbMulticast_group(OSP_group_t* group,
                         int root,
                         int count,
                         OSP_datatype_t osp_type,
                         void* buffer,
                         OSP_handle_t osp_handle);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_Reduce_group(OSP_group_t* group,
                    int root,
                    int count,
                    OSP_reduce_op_t osp_op,
                    OSP_datatype_t osp_type,
                    void* in,
                    void* out);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_NbReduce_group(OSP_group_t* group,
                      int root,
                      int count,
                      OSP_reduce_op_t osp_op,
                      OSP_datatype_t osp_type,
                      void* in,
                      void* out,
                      OSP_handle_t osp_handle);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_Allreduce_group(OSP_group_t* group,
                       int count,
                       OSP_reduce_op_t osp_op,
                       OSP_datatype_t osp_type,
                       void* in,
                       void* out);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_NbAllreduce_group(OSP_group_t* group,
                         int count,
                         OSP_reduce_op_t osp_op,
                         OSP_datatype_t osp_type,
                         void* in,
                         void* out,
                         OSP_handle_t osp_handle);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_Bcast_group(OSP_group_t* group,
                   int root,
                   int bytes,
                   void* buffer);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_NbBcast_group(OSP_group_t* group,
                     int root,
                     int count,
                     void* buffer,
                     OSP_handle_t osp_handle);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_Manytomany_group(OSP_group_t* in_group,
                        OSP_group_t* out_group,
                        int count,
                        OSP_datatype_t osp_type,
                        void* in,
                        void* out);

/**
 * \brief
 *
 * \param[in] group          Group of processes.
 *
 * \see
 *
 * \ingroup MANYTOMANY
 */

int OSP_NbManytomany_group(OSP_group_t* in_group,
                          OSP_group_t* out_group,
                          int count,
                          OSP_datatype_t osp_type,
                          void* in,
                          void* out,
                          OSP_handle_t osp_handle);

/* FIXME: More API functions to come */

/*! @} */

/* ********************************************************************** */
/*                                                                        */
/*               OSP version information                                   */
/*                                                                        */
/* ********************************************************************** */

/* OSP_VERSION is the version string. OSP_NUMVERSION is the
 * numeric version that can be used in numeric comparisons.
 *
 * OSP_VERSION uses the following format:
 * Version: [MAJ].[MIN].[REV][EXT][EXT_NUMBER]
 * Example: 1.0.7rc1 has
 *          MAJ = 1
 *          MIN = 0
 *          REV = 7
 *          EXT = rc
 *          EXT_NUMBER = 1
 *
 * OSP_NUMVERSION will convert EXT to a format number:
 *          ALPHA (a) = 0
 *          BETA (b)  = 1
 *          RC (rc)   = 2
 *          PATCH (p) = 3
 * Regular releases are treated as patch 0
 *
 * Numeric version will have 1 digit for MAJ, 2 digits for MIN, 2
 * digits for REV, 1 digit for EXT and 2 digits for EXT_NUMBER. So,
 * 1.0.7rc1 will have the numeric version 10007201.
 */
#define OSP_VERSION "@OSP_VERSION@"
#define OSP_NUMVERSION @OSP_NUMVERSION@

#define OSP_RELEASE_TYPE_ALPHA  0
#define OSP_RELEASE_TYPE_BETA   1
#define OSP_RELEASE_TYPE_RC     2
#define OSP_RELEASE_TYPE_PATCH  3

#define OSP_CALC_VERSION(MAJOR, MINOR, REVISION, TYPE, PATCH) \
    (((MAJOR) * 10000000) + ((MINOR) * 100000) + ((REVISION) * 1000) + ((TYPE) * 100) + (PATCH))

#if defined(__cplusplus)
}
#endif /* __cplusplus */

#endif /* OSP_H_INCLUDED */
